{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# MLB Team Success Predictor - Model Development\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook develops and trains machine learning models for predicting MLB team success.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Objectives:\\n\",\n",
    "    \"1. Prepare data for modeling\\n\",\n",
    "    \"2. Train classification models for division winners\\n\",\n",
    "    \"3. Train regression models for win totals\\n\",\n",
    "    \"4. Develop milestone prediction models\\n\",\n",
    "    \"5. Implement ensemble methods\\n\",\n",
    "    \"6. Perform hyperparameter tuning\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import libraries\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add project root to path\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import custom modules\\n\",\n",
    "    \"from src.training.train_classifier import ClassifierTrainer\\n\",\n",
    "    \"from src.training.train_regressor import RegressorTrainer\\n\",\n",
    "    \"from src.training.hyperparameter_tuning import HyperparameterTuner\\n\",\n",
    "    \"from src.training.cross_validation import CrossValidator\\n\",\n",
    "    \"from src.models.ensemble_models import MLBEnsembleModel\\n\",\n",
    "    \"from src.visualization.model_plots import ModelVisualizer\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set random seed\\n\",\n",
    "    \"from src.utils.helpers import set_random_seed\\n\",\n",
    "    \"set_random_seed(42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Libraries loaded successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load Engineered Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load engineered data\\n\",\n",
    "    \"data_path = Path('../data/processed/mlb_data_engineered.csv')\\n\",\n",
    "    \"df = pd.read_csv(data_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load feature lists\\n\",\n",
    "    \"with open('../data/processed/feature_lists.json', 'r') as f:\\n\",\n",
    "    \"    feature_lists = json.load(f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Data shape: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Classification features: {len(feature_lists['classification_features'])}\\\")\\n\",\n",
    "    \"print(f\\\"Regression features: {len(feature_lists['regression_features'])}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Filter to modern era for initial models\\n\",\n",
    "    \"modern_df = df[df['year'] >= 2006].copy()\\n\",\n",
    "    \"print(f\\\"\\\\nModern era data shape: {modern_df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Years: {modern_df['year'].min()} - {modern_df['year'].max()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Division Winner Classification\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize classifier trainer\\n\",\n",
    "    \"classifier_trainer = ClassifierTrainer(\\n\",\n",
    "    \"    task_type='division_winner',\\n\",\n",
    "    \"    era_strategy='modern',\\n\",\n",
    "    \"    model_types=['logistic', 'random_forest', 'xgboost', 'lightgbm']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Use custom features\\n\",\n",
    "    \"classification_features = feature_lists['classification_features']\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Prepare data\\n\",\n",
    "    \"X_train, X_test, y_train, y_test, X_val, y_val = classifier_trainer.prepare_data(\\n\"\n",
    "    \"custom_features=classification_features\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Training set shape: {X_train.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Validation set shape: {X_val.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Test set shape: {X_test.shape}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nClass distribution:\\\")\\n\",\n",
    "    \"print(f\\\"Training: {np.bincount(y_train)}\\\")\\n\",\n",
    "    \"print(f\\\"Test: {np.bincount(y_test)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train classification models\\n\",\n",
    "    \"classifier_trainer.train_models(X_train, y_train, X_val, y_val)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Select best model\\n\",\n",
    "    \"best_classifier = classifier_trainer.select_best_model(metric='roc_auc')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display results\\n\",\n",
    "    \"results_df = pd.DataFrame(classifier_trainer.results).T\\n\",\n",
    "    \"print(\\\"\\\\nModel Performance Summary:\\\")\\n\",\n",
    "    \"print(results_df[['accuracy', 'precision', 'recall', 'f1', 'roc_auc']].round(3))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate on test set\\n\",\n",
    "    \"test_results = classifier_trainer.evaluate_on_test_set(X_test, y_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nTest Set Performance:\\\")\\n\",\n",
    "    \"print(f\\\"Accuracy: {test_results['accuracy']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"ROC AUC: {test_results['roc_auc']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Precision: {test_results['precision']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Recall: {test_results['recall']:.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Win Total Regression\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize regression trainer\\n\",\n",
    "    \"regressor_trainer = RegressorTrainer(\\n\",\n",
    "    \"    target_type='wins',\\n\",\n",
    "    \"    era_strategy='modern',\\n\",\n",
    "    \"    model_types=['ridge', 'random_forest', 'xgboost', 'lightgbm']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Prepare data\\n\",\n",
    "    \"X_train_r, X_test_r, y_train_r, y_test_r, X_val_r, y_val_r = regressor_trainer.prepare_data(\\n\",\n",
    "    \"    custom_features=feature_lists['regression_features']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Regression data prepared\\\")\\n\",\n",
    "    \"print(f\\\"Target statistics:\\\")\\n\",\n",
    "    \"print(f\\\"  Train mean: {y_train_r.mean():.1f}, std: {y_train_r.std():.1f}\\\")\\n\",\n",
    "    \"print(f\\\"  Test mean: {y_test_r.mean():.1f}, std: {y_test_r.std():.1f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train regression models\\n\",\n",
    "    \"regressor_trainer.train_models(X_train_r, y_train_r, X_val_r, y_val_r)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Select best model\\n\",\n",
    "    \"best_regressor = regressor_trainer.select_best_model(metric='rmse', minimize=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display results\\n\",\n",
    "    \"reg_results_df = pd.DataFrame(regressor_trainer.results).T\\n\",\n",
    "    \"print(\\\"\\\\nRegression Model Performance:\\\")\\n\",\n",
    "    \"print(reg_results_df[['rmse', 'mae', 'r2', 'within_5_wins', 'within_10_wins']].round(3))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test set evaluation\\n\",\n",
    "    \"test_results_r = regressor_trainer.evaluate_on_test_set(X_test_r, y_test_r)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nTest Set Performance:\\\")\\n\",\n",
    "    \"print(f\\\"RMSE: {test_results_r['rmse']:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"MAE: {test_results_r['mae']:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"R²: {test_results_r['r2']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Within 5 wins: {test_results_r['within_5_wins']:.1%}\\\")\\n\",\n",
    "    \"print(f\\\"Within 10 wins: {test_results_r['within_10_wins']:.1%}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Cross-Validation Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Perform cross-validation for best models\\n\",\n",
    "    \"cv = CrossValidator(cv_strategy='stratified', n_folds=5)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Classification CV\\n\",\n",
    "    \"print(\\\"Classification Model Cross-Validation:\\\")\\n\",\n",
    "    \"cv_results_class = cv.validate_model(\\n\",\n",
    "    \"    classifier_trainer.best_model.model,\\n\",\n",
    "    \"    np.vstack([X_train, X_val]),\\n\",\n",
    "    \"    np.hstack([y_train, y_val]),\\n\",\n",
    "    \"    scoring=['accuracy', 'roc_auc', 'f1']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"for metric in ['accuracy', 'roc_auc', 'f1']:\\n\",\n",
    "    \"    mean = cv_results_class[f'{metric}_mean']\\n\",\n",
    "    \"    std = cv_results_class[f'{metric}_std']\\n\",\n",
    "    \"    print(f\\\"  {metric}: {mean:.3f} (+/- {std:.3f})\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Regression CV\\n\",\n",
    "    \"cv_reg = CrossValidator(cv_strategy='kfold', n_folds=5)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nRegression Model Cross-Validation:\\\")\\n\",\n",
    "    \"cv_results_reg = cv_reg.validate_model(\\n\",\n",
    "    \"    regressor_trainer.best_model.model,\\n\",\n",
    "    \"    np.vstack([X_train_r, X_val_r]),\\n\",\n",
    "    \"    np.hstack([y_train_r, y_val_r]),\\n\",\n",
    "    \"    scoring=['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"  RMSE: {np.sqrt(-cv_results_reg['neg_mean_squared_error_mean']):.2f} \\\"\\n\",\n",
    "    \"      f\\\"(+/- {np.sqrt(cv_results_reg['neg_mean_squared_error_std']):.2f})\\\")\\n\",\n",
    "    \"print(f\\\"  MAE: {-cv_results_reg['neg_mean_absolute_error_mean']:.2f} \\\"\\n\",\n",
    "    \"      f\\\"(+/- {cv_results_reg['neg_mean_absolute_error_std']:.2f})\\\")\\n\",\n",
    "    \"print(f\\\"  R²: {cv_results_reg['r2_mean']:.3f} (+/- {cv_results_reg['r2_std']:.3f})\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Hyperparameter Tuning\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Hyperparameter tuning for best models\\n\",\n",
    "    \"print(\\\"Hyperparameter tuning for XGBoost classifier...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"tuner = HyperparameterTuner(\\n\",\n",
    "    \"    model_class='classification',\\n\",\n",
    "    \"    model_type='xgboost',\\n\",\n",
    "    \"    search_method='random',  # Using random instead of bayesian to avoid skopt\\n\",\n",
    "    \"    n_iter=20,\\n\",\n",
    "    \"    cv_folds=3\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Combine train and validation for tuning\\n\",\n",
    "    \"X_tune = np.vstack([X_train, X_val])\\n\",\n",
    "    \"y_tune = np.hstack([y_train, y_val])\\n\",\n",
    "    \"\\n\",\n",
    "    \"tuning_results = tuner.optimize(X_tune, y_tune)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display tuning results\\n\",\n",
    "    \"print(\\\"\\\\nBest parameters found:\\\")\\n\",\n",
    "    \"for param, value in tuning_results['best_params'].items():\\n\",\n",
    "    \"    print(f\\\"  {param}: {value}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nBest cross-validation score: {tuning_results['best_score']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Ensemble Model Development\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create ensemble model for classification\\n\",\n",
    "    \"from sklearn.ensemble import VotingClassifier\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get top 3 models\\n\",\n",
    "    \"top_models = [\\n\",\n",
    "    \"    (name, model.model) \\n\",\n",
    "    \"    for name, model in classifier_trainer.models.items() \\n\",\n",
    "    \"    if model is not None\\n\",\n",
    "    \"][:3]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create voting ensemble\\n\",\n",
    "    \"ensemble_classifier = MLBEnsembleModel(\\n\",\n",
    "    \"    ensemble_type='voting',\\n\",\n",
    "    \"    task_type='classification',\\n\",\n",
    "    \"    models=top_models\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train ensemble\\n\",\n",
    "    \"ensemble_classifier.train(X_train, y_train, X_val, y_val)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Evaluate\\n\",\n",
    "    \"ensemble_pred = ensemble_classifier.predict(X_test)\\n\",\n",
    "    \"ensemble_proba = ensemble_classifier.predict_proba(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"from sklearn.metrics import accuracy_score, roc_auc_score\\n\",\n",
    "    \"print(\\\"Ensemble Classifier Performance:\\\")\\n\",\n",
    "    \"print(f\\\"  Accuracy: {accuracy_score(y_test, ensemble_pred):.3f}\\\")\\n\",\n",
    "    \"print(f\\\"  ROC AUC: {roc_auc_score(y_test, ensemble_proba[:, 1]):.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Milestone Prediction Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Prepare milestone targets\\n\",\n",
    "    \"from src.models.milestone_predictor import MilestonePredictor\\n\",\n",
    "    \"\\n\",\n",
    "    \"milestone_predictor = MilestonePredictor()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Define milestones\\n\",\n",
    "    \"milestone_columns = ['achieved_90_wins', 'achieved_100_wins', 'scored_800_runs']\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check availability\\n\",\n",
    "    \"available_milestones = [col for col in milestone_columns if col in modern_df.columns]\\n\",\n",
    "    \"print(f\\\"Available milestones: {available_milestones}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(available_milestones) > 0:\\n\",\n",
    "    \"    # Prepare milestone targets\\n\",\n",
    "    \"    milestone_df = modern_df[feature_lists['regression_features'][:30] + available_milestones].dropna()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    X_milestone = milestone_df[feature_lists['regression_features'][:30]].values\\n\",\n",
    "    \"    y_milestone = milestone_df[available_milestones].values\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Milestone data shape: {X_milestone.shape}\\\")\\n\",\n",
    "    \"    print(f\\\"Milestone achievement rates:\\\")\\n\",\n",
    "    \"    for i, milestone in enumerate(available_milestones):\\n\",\n",
    "    \"        print(f\\\"  {milestone}: {y_milestone[:, i].mean():.1%}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Feature Importance Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Get feature importance from best models\\n\",\n",
    "    \"if hasattr(classifier_trainer.best_model, 'get_feature_importance'):\\n\",\n",
    "    \"    importance_df = classifier_trainer.best_model.get_feature_importance()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if importance_df is not None:\\n\",\n",
    "    \"        # Plot feature importance\\n\",\n",
    "    \"        visualizer = ModelVisualizer()\\n\",\n",
    "    \"        fig = visualizer.plot_feature_importance(top_n=20)\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(\\\"\\\\nTop 10 Most Important Features:\\\")\\n\",\n",
    "    \"        print(importance_df.head(10))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Model Comparison\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Compare all models\\n\",\n",
    "    \"comparison_data = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Classification models\\n\",\n",
    "    \"for name, result in classifier_trainer.results.items():\\n\",\n",
    "    \"    if 'error' not in result:\\n\",\n",
    "    \"        comparison_data.append({\\n\",\n",
    "    \"            'Model': f'Class_{name}',\\n\",\n",
    "    \"            'Type': 'Classification',\\n\",\n",
    "    \"            'Accuracy': result.get('accuracy', 0),\\n\",\n",
    "    \"            'ROC_AUC': result.get('roc_auc', 0),\\n\",\n",
    "    \"            'Train_Time': result.get('train_time', 0)\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Regression models  \\n\",\n",
    "    \"for name, result in regressor_trainer.results.items():\\n\",\n",
    "    \"    if 'error' not in result:\\n\",\n",
    "    \"        comparison_data.append({\\n\",\n",
    "    \"            'Model': f'Reg_{name}',\\n\",\n",
    "    \"            'Type': 'Regression',\\n\",\n",
    "    \"            'RMSE': result.get('rmse', 0),\\n\",\n",
    "    \"            'R2': result.get('r2', 0),\\n\",\n",
    "    \"            'Train_Time': result.get('train_time', 0)\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"\\n\",\n",
    "    \"comparison_df = pd.DataFrame(comparison_data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize comparison\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(12, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Classification models\\n\",\n",
    "    \"class_df = comparison_df[comparison_df['Type'] == 'Classification']\\n\",\n",
    "    \"if len(class_df) > 0:\\n\",\n",
    "    \"    ax = axes[0]\\n\",\n",
    "    \"    x = np.arange(len(class_df))\\n\",\n",
    "    \"    width = 0.35\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ax.bar(x - width/2, class_df['Accuracy'], width, label='Accuracy')\\n\",\n",
    "    \"    ax.bar(x + width/2, class_df['ROC_AUC'], width, label='ROC AUC')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ax.set_xlabel('Model')\\n\",\n",
    "    \"    ax.set_ylabel('Score')\\n\",\n",
    "    \"    ax.set_title('Classification Model Comparison')\\n\",\n",
    "    \"    ax.set_xticks(x)\\n\",\n",
    "    \"    ax.set_xticklabels([m.replace('Class_', '') for m in class_df['Model']], rotation=45)\\n\",\n",
    "    \"    ax.legend()\\n\",\n",
    "    \"    ax.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Regression models\\n\",\n",
    "    \"reg_df = comparison_df[comparison_df['Type'] == 'Regression']\\n\",\n",
    "    \"if len(reg_df) > 0:\\n\",\n",
    "    \"    ax = axes[1]\\n\",\n",
    "    \"    x = np.arange(len(reg_df))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ax2 = ax.twinx()\\n\",\n",
    "    \"    ax.bar(x, reg_df['RMSE'], color='red', alpha=0.7, label='RMSE')\\n\",\n",
    "    \"    ax2.plot(x, reg_df['R2'], 'go-', linewidth=2, markersize=8, label='R²')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ax.set_xlabel('Model')\\n\",\n",
    "    \"    ax.set_ylabel('RMSE', color='red')\\n\",\n",
    "    \"    ax2.set_ylabel('R²', color='green')\\n\",\n",
    "    \"    ax.set_title('Regression Model Comparison')\\n\",\n",
    "    \"    ax.set_xticks(x)\\n\",\n",
    "    \"    ax.set_xticklabels([m.replace('Reg_', '') for m in reg_df['Model']], rotation=45)\\n\",\n",
    "    \"    ax.grid(True, alpha=0.3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Combine legends\\n\",\n",
    "    \"    lines1, labels1 = ax.get_legend_handles_labels()\\n\",\n",
    "    \"    lines2, labels2 = ax2.get_legend_handles_labels()\\n\",\n",
    "    \"    ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Save Models\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save best models\\n\",\n",
    "    \"print(\\\"Saving models...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save classification models\\n\",\n",
    "    \"classifier_trainer.save_models(save_all=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save regression models\\n\",\n",
    "    \"regressor_trainer.save_models(save_all=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save training reports\\n\",\n",
    "    \"class_report = classifier_trainer.generate_training_report()\\n\",\n",
    "    \"reg_report = regressor_trainer.generate_training_report()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save combined report\\n\",\n",
    "    \"combined_report = {\\n\",\n",
    "    \"    'classification': class_report,\\n\",\n",
    "    \"    'regression': reg_report,\\n\",\n",
    "    \"    'training_date': pd.Timestamp.now().isoformat()\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"report_path = Path('../models/training_report.json')\\n\",\n",
    "    \"with open(report_path, 'w') as f:\\n\",\n",
    "    \"    json.dump(combined_report, f, indent=2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nModels and reports saved successfully!\\\")\\n\",\n",
    "    \"print(f\\\"Training report saved to: {report_path}\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
