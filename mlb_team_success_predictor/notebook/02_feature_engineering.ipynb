{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4afdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# MLB Team Success Predictor - Feature Engineering\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook creates engineered features to improve model performance.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Objectives:\\n\",\n",
    "    \"1. Create performance-based features\\n\",\n",
    "    \"2. Engineer historical/lag features\\n\",\n",
    "    \"3. Generate era-adjusted statistics\\n\",\n",
    "    \"4. Build milestone and target variables\\n\",\n",
    "    \"5. Validate and select features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import libraries\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add project root to path\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import custom modules\\n\",\n",
    "    \"from src.data.data_preprocessor import DataPreprocessor\\n\",\n",
    "    \"from src.data.feature_engineering import FeatureEngineer\\n\",\n",
    "    \"from src.utils.config import CLASSIFICATION_FEATURES, REGRESSION_FEATURES\\n\",\n",
    "    \"from src.utils.constants import ERA_DEFINITIONS\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set up visualization\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8-darkgrid')\\n\",\n",
    "    \"%matplotlib inline\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Libraries loaded successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load and Preprocess Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load data from previous notebook\\n\",\n",
    "    \"data_path = Path('../data/processed/mlb_data_explored.csv')\\n\",\n",
    "    \"df = pd.read_csv(data_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Data loaded: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Years: {df['year'].min()} - {df['year'].max()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Preprocess data\\n\",\n",
    "    \"preprocessor = DataPreprocessor(era_strategy='all')  # Keep all eras for now\\n\",\n",
    "    \"df_processed = preprocessor.preprocess(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Processed data shape: {df_processed.shape}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nNew columns from preprocessing:\\\")\\n\",\n",
    "    \"new_cols = set(df_processed.columns) - set(df.columns)\\n\",\n",
    "    \"print(list(new_cols))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Basic Performance Features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize feature engineer\\n\",\n",
    "    \"engineer = FeatureEngineer(include_era_features=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Engineer all features\\n\",\n",
    "    \"df_engineered = engineer.engineer_features(df_processed)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Engineered data shape: {df_engineered.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Total new features created: {len(df_engineered.columns) - len(df_processed.columns)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display feature groups\\n\",\n",
    "    \"feature_groups = engineer.get_feature_groups()\\n\",\n",
    "    \"\\n\",\n",
    "    \"for group_name, features in feature_groups.items():\\n\",\n",
    "    \"    print(f\\\"\\\\n{group_name.upper()} Features ({len(features)}):\\\")\\n\",\n",
    "    \"    print(f\\\"  Sample: {features[:5]}...\\\" if len(features) > 5 else f\\\"  {features}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Feature Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze new features\\n\",\n",
    "    \"performance_features = feature_groups.get('performance', [])\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(performance_features) > 0:\\n\",\n",
    "    \"    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\\n\",\n",
    "    \"    axes = axes.ravel()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i, feature in enumerate(performance_features[:4]):\\n\",\n",
    "    \"        if feature in df_engineered.columns:\\n\",\n",
    "    \"            ax = axes[i]\\n\",\n",
    "    \"            df_engineered[feature].hist(bins=30, ax=ax, edgecolor='black', alpha=0.7)\\n\",\n",
    "    \"            ax.set_title(f'Distribution of {feature}')\\n\",\n",
    "    \"            ax.set_xlabel(feature)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Add mean line\\n\",\n",
    "    \"            mean_val = df_engineered[feature].mean()\\n\",\n",
    "    \"            ax.axvline(mean_val, color='red', linestyle='--', linewidth=2)\\n\",\n",
    "    \"            ax.text(mean_val, ax.get_ylim()[1]*0.9, f'Mean: {mean_val:.3f}', \\n\",\n",
    "    \"                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check for missing values in engineered features\\n\",\n",
    "    \"missing_features = df_engineered[engineer.feature_names].isnull().sum()\\n\",\n",
    "    \"missing_features = missing_features[missing_features > 0].sort_values(ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(missing_features) > 0:\\n\",\n",
    "    \"    print(\\\"Features with missing values:\\\")\\n\",\n",
    "    \"    print(missing_features.head(10))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Visualize missing pattern\\n\",\n",
    "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"    missing_pct = (missing_features / len(df_engineered)) * 100\\n\",\n",
    "    \"    missing_pct.head(20).plot(kind='bar')\\n\",\n",
    "    \"    plt.title('Top 20 Features with Missing Values')\\n\",\n",
    "    \"    plt.xlabel('Feature')\\n\",\n",
    "    \"    plt.ylabel('Missing Percentage')\\n\",\n",
    "    \"    plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Historical Features Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze historical features\\n\",\n",
    "    \"historical_features = [f for f in engineer.feature_names if 'prev_' in f or '_avg' in f]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Historical features created: {len(historical_features)}\\\")\\n\",\n",
    "    \"print(f\\\"Sample: {historical_features[:10]}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize relationship between current and previous year performance\\n\",\n",
    "    \"if 'prev_wins' in df_engineered.columns:\\n\",\n",
    "    \"    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Scatter plot\\n\",\n",
    "    \"    ax = axes[0]\\n\",\n",
    "    \"    valid_data = df_engineered.dropna(subset=['wins', 'prev_wins'])\\n\",\n",
    "    \"    ax.scatter(valid_data['prev_wins'], valid_data['wins'], alpha=0.5, s=10)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add regression line\\n\",\n",
    "    \"    from scipy import stats\\n\",\n",
    "    \"    slope, intercept, r_value, _, _ = stats.linregress(valid_data['prev_wins'], valid_data['wins'])\\n\",\n",
    "    \"    x_line = np.linspace(valid_data['prev_wins'].min(), valid_data['prev_wins'].max(), 100)\\n\",\n",
    "    \"    y_line = slope * x_line + intercept\\n\",\n",
    "    \"    ax.plot(x_line, y_line, 'r-', linewidth=2, label=f'R² = {r_value**2:.3f}')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ax.set_xlabel('Previous Year Wins')\\n\",\n",
    "    \"    ax.set_ylabel('Current Year Wins')\\n\",\n",
    "    \"    ax.set_title('Year-over-Year Win Correlation')\\n\",\n",
    "    \"    ax.legend()\\n\",\n",
    "    \"    ax.grid(True, alpha=0.3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Distribution of win changes\\n\",\n",
    "    \"    ax = axes[1]\\n\",\n",
    "    \"    if 'wins_change' in df_engineered.columns:\\n\",\n",
    "    \"        win_changes = df_engineered['wins_change'].dropna()\\n\",\n",
    "    \"        ax.hist(win_changes, bins=30, edgecolor='black', alpha=0.7)\\n\",\n",
    "    \"        ax.axvline(0, color='red', linestyle='--', linewidth=2)\\n\",\n",
    "    \"        ax.set_xlabel('Change in Wins')\\n\",\n",
    "    \"        ax.set_ylabel('Frequency')\\n\",\n",
    "    \"        ax.set_title('Distribution of Year-over-Year Win Changes')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Add statistics\\n\",\n",
    "    \"        mean_change = win_changes.mean()\\n\",\n",
    "    \"        std_change = win_changes.std()\\n\",\n",
    "    \"        ax.text(0.05, 0.95, f'Mean: {mean_change:.1f}\\\\nStd: {std_change:.1f}',\\n\",\n",
    "    \"               transform=ax.transAxes, verticalalignment='top',\\n\",\n",
    "    \"               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Era-Adjusted Features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze era-adjusted features\\n\",\n",
    "    \"era_features = [f for f in engineer.feature_names if 'era' in f]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Era-adjusted features: {len(era_features)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Compare raw vs era-adjusted metrics\\n\",\n",
    "    \"if 'wins_era_zscore' in df_engineered.columns:\\n\",\n",
    "    \"    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Raw wins by era\\n\",\n",
    "    \"    ax = axes[0]\\n\",\n",
    "    \"    df_engineered.boxplot(column='wins', by='era', ax=ax)\\n\",\n",
    "    \"    ax.set_title('Raw Wins by Era')\\n\",\n",
    "    \"    ax.set_xlabel('Era')\\n\",\n",
    "    \"    ax.set_ylabel('Wins')\\n\",\n",
    "    \"    plt.suptitle('')  # Remove default title\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Era-adjusted wins (z-score)\\n\",\n",
    "    \"    ax = axes[1]\\n\",\n",
    "    \"    df_engineered.boxplot(column='wins_era_zscore', by='era', ax=ax)\\n\",\n",
    "    \"    ax.set_title('Era-Adjusted Wins (Z-Score)')\\n\",\n",
    "    \"    ax.set_xlabel('Era')\\n\",\n",
    "    \"    ax.set_ylabel('Z-Score')\\n\",\n",
    "    \"    ax.axhline(0, color='red', linestyle='--', alpha=0.5)\\n\",\n",
    "    \"    plt.suptitle('')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Target Variable Creation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze target variables\\n\",\n",
    "    \"target_vars = ['is_division_winner', 'made_playoffs', 'achieved_90_wins', \\n\",\n",
    "    \"               'achieved_100_wins', 'scored_800_runs']\\n\",\n",
    "    \"\\n\",\n",
    "    \"target_summary = []\\n\",\n",
    "    \"for target in target_vars:\\n\",\n",
    "    \"    if target in df_engineered.columns:\\n\",\n",
    "    \"        positive_rate = df_engineered[target].mean()\\n\",\n",
    "    \"        target_summary.append({\\n\",\n",
    "    \"            'Target': target,\\n\",\n",
    "    \"            'Positive_Rate': positive_rate,\\n\",\n",
    "    \"            'Positive_Count': df_engineered[target].sum(),\\n\",\n",
    "    \"            'Total_Count': df_engineered[target].count()\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"\\n\",\n",
    "    \"target_df = pd.DataFrame(target_summary)\\n\",\n",
    "    \"print(\\\"Target Variable Summary:\\\")\\n\",\n",
    "    \"print(target_df)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize target distributions\\n\",\n",
    "    \"fig, ax = plt.subplots(figsize=(10, 6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(target_df) > 0:\\n\",\n",
    "    \"    target_df.plot(x='Target', y='Positive_Rate', kind='bar', ax=ax)\\n\",\n",
    "    \"    ax.set_title('Target Variable Positive Class Rates')\\n\",\n",
    "    \"    ax.set_xlabel('Target Variable')\\n\",\n",
    "    \"    ax.set_ylabel('Positive Rate')\\n\",\n",
    "    \"    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add percentage labels\\n\",\n",
    "    \"    for i, v in enumerate(target_df['Positive_Rate']):\\n\",\n",
    "    \"        ax.text(i, v + 0.01, f'{v:.1%}', ha='center')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Feature Correlation Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Select features for modeling\\n\",\n",
    "    \"classification_features = engineer.select_features_for_model('division_winner')\\n\",\n",
    "    \"regression_features = engineer.select_features_for_model('win_total')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Classification features selected: {len(classification_features)}\\\")\\n\",\n",
    "    \"print(f\\\"Regression features selected: {len(regression_features)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check feature availability\\n\",\n",
    "    \"available_class_features = [f for f in classification_features if f in df_engineered.columns]\\n\",\n",
    "    \"available_reg_features = [f for f in regression_features if f in df_engineered.columns]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nAvailable classification features: {len(available_class_features)}\\\")\\n\",\n",
    "    \"print(f\\\"Available regression features: {len(available_reg_features)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Feature correlation with targets\\n\",\n",
    "    \"if 'is_division_winner' in df_engineered.columns and len(available_class_features) > 0:\\n\",\n",
    "    \"    # Calculate correlations\\n\",\n",
    "    \"    feature_corrs = []\\n\",\n",
    "    \"    for feature in available_class_features[:20]:  # Top 20 features\\n\",\n",
    "    \"        if feature in df_engineered.columns:\\n\",\n",
    "    \"            corr = df_engineered[feature].corr(df_engineered['is_division_winner'])\\n\",\n",
    "    \"            feature_corrs.append({'Feature': feature, 'Correlation': corr})\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    corr_df = pd.DataFrame(feature_corrs).sort_values('Correlation', key=abs, ascending=False)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot\\n\",\n",
    "    \"    plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"    plt.barh(corr_df['Feature'], corr_df['Correlation'])\\n\",\n",
    "    \"    plt.xlabel('Correlation with Division Winner')\\n\",\n",
    "    \"    plt.title('Feature Correlations with Division Winner Target')\\n\",\n",
    "    \"    plt.axvline(0, color='black', linestyle='-', linewidth=0.5)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Color bars based on positive/negative correlation\\n\",\n",
    "    \"    colors = ['green' if x > 0 else 'red' for x in corr_df['Correlation']]\\n\",\n",
    "    \"    bars = plt.gca().patches\\n\",\n",
    "    \"    for bar, color in zip(bars, colors):\\n\",\n",
    "    \"        bar.set_facecolor(color)\\n\",\n",
    "    \"        bar.set_alpha(0.7)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Feature Importance Preview\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Quick feature importance check using Random Forest\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestClassifier\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Prepare data for quick test\\n\",\n",
    "    \"if 'is_division_winner' in df_engineered.columns and len(available_class_features) > 10:\\n\",\n",
    "    \"    # Remove rows with missing values\\n\",\n",
    "    \"    test_features = available_class_features[:30]  # Limit features for quick test\\n\",\n",
    "    \"    test_df = df_engineered[test_features + ['is_division_winner']].dropna()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if len(test_df) > 100:\\n\",\n",
    "    \"        X = test_df[test_features]\\n\",\n",
    "    \"        y = test_df['is_division_winner']\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Quick train/test split\\n\",\n",
    "    \"        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Train simple model\\n\",\n",
    "    \"        rf = RandomForestClassifier(n_estimators=50, random_state=42)\\n\",\n",
    "    \"        rf.fit(X_train, y_train)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Get feature importance\\n\",\n",
    "    \"        importance_df = pd.DataFrame({\\n\",\n",
    "    \"            'feature': test_features,\\n\",\n",
    "    \"            'importance': rf.feature_importances_\\n\",\n",
    "    \"        }).sort_values('importance', ascending=False)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Plot top 15 features\\n\",\n",
    "    \"        plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"        top_features = importance_df.head(15)\\n\",\n",
    "    \"        plt.barh(range(len(top_features)), top_features['importance'])\\n\",\n",
    "    \"        plt.yticks(range(len(top_features)), top_features['feature'])\\n\",\n",
    "    \"        plt.xlabel('Importance')\\n\",\n",
    "    \"        plt.title('Preliminary Feature Importance (Random Forest)')\\n\",\n",
    "    \"        plt.gca().invert_yaxis()\\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"\\\\nQuick model accuracy: {rf.score(X_test, y_test):.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Feature Engineering Summary\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate feature engineering summary\\n\",\n",
    "    \"summary = {\\n\",\n",
    "    \"    'Total Features Created': len(engineer.feature_names),\\n\",\n",
    "    \"    'Performance Features': len(feature_groups.get('performance', [])),\\n\",\n",
    "    \"    'Efficiency Features': len(feature_groups.get('efficiency', [])),\\n\",\n",
    "    \"    'Historical Features': len(feature_groups.get('historical', [])),\\n\",\n",
    "    \"    'Era-Adjusted Features': len(feature_groups.get('era_adjusted', [])),\\n\",\n",
    "    \"    'Target Variables': len([col for col in df_engineered.columns if col.startswith(('is_', 'achieved_', 'made_'))])\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nFeature Engineering Summary:\\\")\\n\",\n",
    "    \"for key, value in summary.items():\\n\",\n",
    "    \"    print(f\\\"- {key}: {value}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save engineered data\\n\",\n",
    "    \"output_path = Path('../data/processed/mlb_data_engineered.csv')\\n\",\n",
    "    \"df_engineered.to_csv(output_path, index=False)\\n\",\n",
    "    \"print(f\\\"\\\\nEngineered data saved to {output_path}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save feature lists\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"\\n\",\n",
    "    \"feature_lists = {\\n\",\n",
    "    \"    'all_features': engineer.feature_names,\\n\",\n",
    "    \"    'classification_features': available_class_features,\\n\",\n",
    "    \"    'regression_features': available_reg_features,\\n\",\n",
    "    \"    'feature_groups': {k: v for k, v in feature_groups.items()}\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"feature_path = Path('../data/processed/feature_lists.json')\\n\",\n",
    "    \"with open(feature_path, 'w') as f:\\n\",\n",
    "    \"    json.dump(feature_lists, f, indent=2)\\n\",\n",
    "    \"print(f\\\"Feature lists saved to {feature_path}\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
